{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction or Motivation or Problem Statement\n",
    "We are trying to train a facial recognition neural network. To be able to identify people in pictures \n",
    "with the people inside a database.\n",
    "\n",
    "\n",
    "## Data Sources\n",
    "The data used for training can be found at:\n",
    "\n",
    "AT&T dataset - https://github.com/maticvl/dataHacker/blob/master/DATA/at%26t.zip \n",
    "\n",
    "(gray-scaled dataset with 400 samples)\n",
    "\n",
    "lfw dataset - https://www.kaggle.com/datasets/atulanandjha/lfwpeople\n",
    "\n",
    "(colored dataset with 13000+ images)\n",
    "\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "Each class in the dataset is a person's name with 10 grey pictures of their portrait.\n",
    "\n",
    "For data preparation the image transformed to size 100 x 100 to fit the model and changed into grey pictures and then turned into 1x100x100 tensor.\n",
    "\n",
    "In SiameseNetworkDataset's getitem it choices at 50/50 chance to be in the same class or different class and by checking if's their folder's name is the same it produces a lebel of 1 or 0.\n",
    "\n",
    "\n",
    "## Model\n",
    "At the start we just wanted to make a basic facial recognition neural network to work, that's why we chose Siamese with contrastive loss with grey pictures, it is easy to understant and easy to implement.\n",
    "\n",
    "The model used is the Siamese neural network, it has inputs as 2 images. Both images will pass through the same convolution neural network with fully connected layers at the end to produce 2 values as output. And the euclidean distance between the two images is the dissimilaity score (because both pictures went through the same neural network and if the images are in the same class it should have small distance score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbsyvXYzD6My",
    "outputId": "699b10b8-4297-4f16-98dc-08c073314df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ---------------------------------------------------------------------------------------\n",
      "1 ---------------------------------------------------------------------------------------\n",
      "2 ---------------------------------------------------------------------------------------\n",
      "3 ---------------------------------------------------------------------------------------\n",
      "4 ---------------------------------------------------------------------------------------\n",
      "5 ---------------------------------------------------------------------------------------\n",
      "6 ---------------------------------------------------------------------------------------\n",
      "Epoch number 0\n",
      " Current loss 0.4860076904296875\n",
      "\n",
      "Epoch number 1\n",
      " Current loss 0.8250916600227356\n",
      "\n",
      "Epoch number 2\n",
      " Current loss 0.6730691194534302\n",
      "\n",
      "Epoch number 3\n",
      " Current loss 0.6003469228744507\n",
      "\n",
      "Epoch number 4\n",
      " Current loss 0.5684418678283691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Showing images\n",
    "def imshow(img, text=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "        \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "# Plotting data\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()\n",
    "\n",
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self,imageFolderDataset,transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "\n",
    "        #We need to approximately 50% of images to be in the same class\n",
    "        should_get_same_class = random.randint(0,1) \n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                #Look untill the same class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] == img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "\n",
    "            while True:\n",
    "                #Look untill a different class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] != img1_tuple[1]:\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)\n",
    "\n",
    "# Load the training dataset\n",
    "folder_dataset = datasets.ImageFolder(root=\"./data/faces/training/\")\n",
    "\n",
    "# Resize the images and transform to tensors\n",
    "transformation = transforms.Compose([transforms.Resize((100,100)),\n",
    "                                     transforms.ToTensor()\n",
    "                                    ])\n",
    "\n",
    "# Initialize the network\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
    "                                        transform=transformation)\n",
    "\n",
    "# create siameseNetwork\n",
    "class SiameseNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 384, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(384, 384, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "            \n",
    "        )\n",
    "\n",
    "        # Setting up the Fully Connected Layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(13824, 6200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(6200, 3100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(3100, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(256,2)\n",
    "        )\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        # This function will be called for both images\n",
    "        # Its output is used to determine the similiarity\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        #output = torch.flatten(output, 1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # In this function we pass in both images and obtain both vectors\n",
    "        # which are returned\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "\n",
    "        return output1, output2\n",
    "    \n",
    "# Define the Contrastive Loss Function\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "      # Calculate the euclidean distance and calculate the contrastive loss\n",
    "      euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "\n",
    "      loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "      return loss_contrastive\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        batch_size=64)\n",
    "\n",
    "\n",
    "net = SiameseNetwork()\n",
    "net.load_state_dict(torch.load('greymodel_more_save.pt'))\n",
    "net.eval()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0005 )\n",
    "\n",
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "\n",
    "# Iterate throught the epochs\n",
    "for epoch in range(50):\n",
    "    # Iterate over batches\n",
    "    for i, (img0, img1, label) in enumerate(train_dataloader, 0):\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass in the two images into the network and obtain two outputs\n",
    "        output1, output2 = net(img0, img1)\n",
    "\n",
    "        # Pass the outputs of the networks and label into the loss function\n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "\n",
    "        # Calculate the backpropagation\n",
    "        loss_contrastive.backward()\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Every 10 batches print out the loss\n",
    "        if i % 10 == 0 :\n",
    "            print(f\"Epoch number {epoch}\\n Current loss {loss_contrastive.item()}\\n\")\n",
    "            iteration_number += 10\n",
    "\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "\n",
    "show_plot(counter, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VmnqIenD6M6"
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'greymodel_more_2_save.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wl0amKEFD6M7"
   },
   "outputs": [],
   "source": [
    "model = SiameseNetwork()\n",
    "model.load_state_dict(torch.load('greymodel_save.pt'))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "greymod.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
